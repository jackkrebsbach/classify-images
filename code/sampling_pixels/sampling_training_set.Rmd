---
title: "Sampling Training Set"
author: "Jackson Krebsbach"
date: "6/1/2021"
output: html_document
---


#Setup
```{r setup, include=FALSE, echo = FALSE}
require("knitr")
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

#Load Libraries and functions
```{r,echo = FALSE, results='hide', message=FALSE}
rm(list = ls())
gc()
library(sf)
library(raster)
library(RStoolbox)
library(tidyverse)
library(jsonlite)
library(magrittr)
library(tictoc)
source("code/helpers/veggie_functions.R")
```


# Extract all pixels from polygons
```{r}
extract_points_from_quadrat <- function(quadrat_sfc){
  quadrat_sfc %>% 
    pmap(.f = extract_points) %>% 
    bind_rows()
}

extract_points <- function(label, imagePath, polys, area, quadrat, poly_num) {
  
  poly_info <- tibble(label, quadrat, poly_num)
  
  polys <- polys %>%
    st_sfc() %>%
    st_as_sf()
  
  file_name_to_extract <-paste0('clean_data/quadrats/quadrat', toString(33+quadrat),"/" , imagePath)
  
  img <- file_name_to_extract  %>%
    brick()
  
  extent(img) <- c(0,4032,0,3024)
  
  raster::extract(img, polys, cellnumbers = TRUE )[[1]]  %>%
    as_tibble() %>%
    mutate(across(.cols = everything(), .fns =  as.integer)) %>%
    full_join(poly_info, by = character()) %>%
    mutate(label = as.factor(label))
}
```


#Extract all pixels from polygons functions
```{r}
layers <- list('hsv_seg_6_4.5_50', "hsv_contrast_L3_W7")

for(layer in layers){
  #Create files to read and write
  raster_layer <- paste0(layer,".tif")
  file_name <- paste0(layer,".rds")
  
  polys_sf <- polys_sf %>%
    dplyr::select(-train_val) %>%
    group_split(quadrat) %>%
    map(~mutate(.x, imagePath = raster_layer)) 
  
  #Time how long it takes with tic(), toc()
  tic()
  
  polys_sf[1:50] %>%
    map(.f = extract_points_from_quadrat) -> quadrat_pts
  
  quadrat_pts %>%
    saveRDS(file = paste0("clean_data/pixel_values/", file_name))
  
  toc()
}
```


## Join Pixel Values

```{r}
poly_key <- polys_sf %>% 
  st_drop_geometry() %>%
  dplyr::select(c(quadrat, poly_num, area, train_val)) %>%
  as_tibble()

hsv <- readRDS('./clean_data/pixel_values/hsv.rds') %>%
  bind_rows() %>%
  full_join(poly_key, by = c('quadrat', 'poly_num'))

hsv_seg <- readRDS('./clean_data/pixel_values/hsv_seg_6_4.5_50.rds') %>%
  bind_rows() %>%
  full_join(poly_key, by = c('quadrat', 'poly_num'))

hsv_contrast <- readRDS('./clean_data/pixel_values/hsv_contrast_L3_W7.rds') %>%
  bind_rows() %>%
  full_join(poly_key, by = c('quadrat', 'poly_num'))


hsv %>% left_join(hsv_seg) %>%
  left_join(hsv_contrast) %>%
  relocate(c(cell, quadrat, poly_num, area), .after = hsv_contrast_L3_W7) %>%
  relocate(label, .before = hsv.1) -> pixels

saveRDS(pixels, './clean_data/pixel_values/pixels.rds')
```


## Sample All Polygons

```{r, echo=FALSE}
sample_polygons <- function(directory, quadrats) {
  quadrats[[directory]] %>%
    label_me_json_to_sf() %>%
    dplyr::mutate(quadrat = directory, area = st_area(.$polys)) %>%
    dplyr::mutate(label = case_when(label == "live Marram grass" ~ "live vegetation", TRUE ~ label)) %>%
    filter(is.element(label, c("live vegetation", "dead vegetation", "sand"))) %>%
    mutate(poly_num = c(1:length(polys)))
}

polys_sf <- seq(1, 50) %>%
  lapply(
    FUN = sample_polygons,
    quadrats = sprintf("clean_data/quadrats/quadrat%02d/rgb.json", seq(34, 83, 1))
  ) %>%
  bind_rows()

polys_sf  %<>%
  group_by(quadrat) %>%
  mutate(poly_num = c(1:length(polys))) 

(polys_sf %>% st_make_valid() %>% count(label) -> label_counts)

```


# Split Sets By Polygon Summary

```{r}
set.seed(8765309)

train_val_split_summary <- tibble(
  label = factor(c("dead vegetation", "live vegetation", "sand")),
  train_n = c(302, 222, 189),
  val_n = c(181, 133, 113),
  test_n = c(121, 89, 76),
)

# check to make sure I can subtract
label_counts %>%
  full_join(train_val_split_summary) %>%
  mutate(N = train_n + test_n + val_n)

polys_sf %<>% bind_rows() %>%
  train_val_split_polys(train_val_split_summary)

# check to make sure it agrees
polys_sf %>% st_make_valid() %>%
  group_by(train_val) %>%
  count(label)

```


#Sample pixels to extract data from
```{r}
NUM_TRAIN_PTS <- 50
NUM_VAL_PTS <- 25
NUM_TEST_PTS <- 15

train_sf <- polys_sf %>% filter(train_val == "train")

train_pts <- train_sf %>%
  group_by(label, quadrat, poly_num, area) %>%
  summarize(pts = st_sample(polys, size = NUM_TRAIN_PTS))


val_sf <- polys_sf %>% filter(train_val == "val")

val_pts <- val_sf %>%
  group_by(label, quadrat, poly_num, area) %>%
  summarize(pts = st_sample(polys, size = NUM_VAL_PTS))


test_sf <- polys_sf %>% filter(train_val == "test")

test_pts <- test_sf %>%
  group_by(label, quadrat, poly_num, area) %>%
  summarize(pts = st_sample(polys, size = NUM_TEST_PTS))
```

#Area by class
```{r}
ggplot(poly_summary, aes(x = area_class, y = area, label = n)) +
  geom_col()  +
  geom_text(nudge_y = 10000, size = 2) +
  theme(axis.text.x = element_text(angle = 75, hjust=1,size = 5)) +
  facet_grid(.~label, scales = "free_y")

```

#Area by class
```{r}
#scaleFUN <- function(x) sprintf("%.2f", x)
polys_sf %>% group_by(label) %>% summarize(area = sum(area)) -> area_summary
ggplot(area_summary) +
  geom_col(mapping = aes(x = label, y = area, fill= label)) +
  scale_fill_manual(values=c("#b7a386", "#5a6233", "#5e4a31"))# +
  #scale_y_continuous(labels = scaleFUN)
```

#Look at training points 
```{r}
im_path <- "clean_data/quadrats/quadrat34/yuv.tif"
json_path <- "clean_data/quadrats/quadrat34/rgb.json"

sampled_pts <- test_pts %>% filter(quadrat == 1)


p <- plot_labeled(im_path, json_path, maxpixels = 1e+6)
p + geom_sf(data = sampled_pts, color = "black", size = 0.05)
# ggsave("outputs/test_labeled_training_pts.pdf")
```


#Extract Pixels Function
```{r}
extract_values <- function(dir, pts, quadrats) {
  #List images in the directory and get the pts in a quadrat
  pts <- pts %>% filter(quadrat == dir)
  files <- list("hsv.tif", "lab.tif", "rgb.tif",
                 "rgb_seg_6_4.5_50.tif", "hsv_seg_6_4.5_50.tif", "lab_seg_6_4.5_50.tif",
                "hsv_contrast_L3_W5.tif", "hsv_contrast_L3_W3.tif", "hsv_contrast_L3_W7.tif")
  
  images <- paste0(quadrats[dir], files)
  
  train_ras_mat <- images %>% 
    map(.f = function(image_file, pts){
     image_file %>%
       brick() -> ras
       extent(ras) <- raster::extent(c(0, 4032, 0, 3024))
       ras %>%
         raster::extract(y = pts) %>% as_tibble()
     }, pts = pts)  %>% bind_cols()

  #Bind the pixel values to corresponding label by column
  pts %>% cbind(train_ras_mat) %>%
    st_drop_geometry() %>%
    select(-quadrat) %>%
    as_tibble() %>%
    drop_na() 
}
```

#Extract pixel values from all directories
```{r}
quadrats <-  sprintf("clean_data/quadrats/quadrat%02d/", seq(34, 83, 1))

#extract_values function comes from helpers
train_values <- train_pts$quadrat %>%
  unique() %>%
  map(
    .f = extract_values, pts = train_pts,
    quadrats = quadrats
  ) %>%
  bind_rows()

val_values <- val_pts$quadrat %>%
  unique() %>%
  map(
    .f = extract_values, pts = val_pts,
    quadrats = quadrats
  ) %>%
  bind_rows()

test_values <- test_pts$quadrat %>%
  unique() %>%
  map(
    .f = extract_values, pts = test_pts,
    quadrats = quadrats
  ) %>%
  bind_rows()

# Check how many points in each set
count(train_values, label)
 count(val_values, label)
 count(test_values, label)
```


#Save Data
```{r}
save(train_values, file = "clean_data/rdata/math_fest/train_values.RData")
save(val_values, file = "clean_data/rdata/math_fest/val_values.RData")
save(test_values, file = "clean_data/rdata/math_fest/test_values.RData")
```


