---
title: "training_classifier"
author: "Jackson Krebsbach"
date: "7/31/2021"
output: html_document
---

## Load Libraries
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir=normalizePath("../..")) #set working directory to the project directory
library(tidyverse)
library(tidymodels)
library(ranger)
library(randomForest)
library(RStoolbox)
library(sf)
```


## Source Files and build classifier model
```{r, echo=FALSE, results=FALSE, message=FALSE, include=FALSE }
source('./code/helpers/classify_helpers.R')
show_engines("rand_forest")
rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()
```


## Get a list of clean pixels that make up a training, validation, and testing set
```{r}
'%!in%' <- function(x,y)!('%in%'(x,y))

#List of all the polygons that have errors or need to be removed
problem_polygons <- read_csv("clean_data/polygons_to_remove.csv") %>%
  mutate(quadrat = quadrat - 33) %>%
  mutate(key = paste0(quadrat,"_",poly_num))


#List of class changes that need to be done on the polygons
poly_classes_to_change <- read_csv("clean_data/polygon_class_changes.csv") %>%
  mutate(quadrat = as.numeric(quadrat - 33)) %>%
  mutate(key = paste0(quadrat,"_",poly_num))%>%
  dplyr::select(c(key, class_to_change_to))


#All the pixel values from every polygon
pixels <- readRDS('clean_data/rdata/pixel_values/features/poly_pixels.rds') %>%
  as_tibble() %>% 
  mutate(key = paste0(quadrat,"_",poly_num)) %>%
  filter(key %!in% problem_polygons$key) 


# Remove the polygons with errors and mutate the ones that need a class change
clean_pixels <- pixels %>%
  left_join(poly_classes_to_change) %>%
  mutate(label = as.factor(label), class_to_change_to = as.factor(class_to_change_to)) %>%
  mutate(label = case_when(is.na(class_to_change_to) ~ label,
                           !is.na(class_to_change_to) ~ class_to_change_to)) %>%
  dplyr::select(-class_to_change_to)
```


## Train test split
```{r}
full_train <- clean_pixels %>% 
  filter(train_val == 'train')
full_val <- clean_pixels %>%
  filter(train_val == 'val')
```


## Sample 10 pixels per polygon 
```{r}
PIXELS <- 50000

subset_training <- full_train %>%
  group_by(label) %>%
  slice_sample(n = PIXELS) %>% # n is the number of pixels per polygon that we want to sample
  ungroup()
#conf_matrix <- classify_train_val(train = subset_training, val = full_val)
```


## Get Percentage Confusion Matrix
```{r}
# Takes in direct ouput from conf_mat
get_percentage_confusion_matrix <- function(conf_matrix){
  
  conf_matrix[[1]] %>%
    as_tibble() %>%
    pivot_wider(names_from = Truth, values_from = n) %>%
    mutate(`dead vegetation` = `dead vegetation`/ sum(`dead vegetation`),
           `live vegetation` = `live vegetation`/ sum(`live vegetation`),
           sand = sand/sum(sand)) %>%
    return()
}
```


## Train on train set and predict on validation set
```{r}
OUT_FILE <-"all_pixels"

train <- full_train
val <- full_val

rf_fit <- rf_pixel_model %>% fit(label ~ hsv_seg_6_4.5_50.1 + hsv_seg_6_4.5_50.2 + hsv_seg_6_4.5_50.3 +
                                   hsv_contrast_L3_W7 + hsv.1 + hsv.2 + hsv.3, data = train)

val <- val %>%
  drop_na()

val_pred <- predict(rf_fit, val) %>% 
  bind_cols(predict(rf_fit, val, type = "prob")) %>%
  bind_cols(val %>% dplyr::select(label,quadrat, poly_num, area)) 

val_pred %>%
  conf_mat(truth = label, .pred_class) -> val_confusion_matrix

val_pred %>%
  accuracy(truth = label, .pred_class) -> val_accuracy

train_accuracy <- 1 - rf_fit$fit$prediction.error


c <- val_confusion_matrix %>% get_percentage_confusion_matrix()

saveRDS(val_pred, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_val_pixels.rds" ))
saveRDS(c, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_percentage_conf_mat.rds" ))
saveRDS(val_confusion_matrix, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_count_conf_mat.rds" ))
saveRDS(val_accuracy, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_validation_accuracy.rds" ))
```





```{r}
ten_pixels <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(28783, 667, 2606),
                     live_veg= c(894,75203, 73),
                     sand = c(9833, 377, 345554))

fifty <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(27642, 755,3659 ),
                     live_veg= c(883,75193, 94),
                     sand = c(1442, 182, 354140))

full_train <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(27586, 797, 3673),
                     live_veg= c(883, 75188, 99),
                     sand = c(1399, 182, 354183))
fifty
```


```{r}
options(digits = 2)
ten_pixels %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> ten_sum

fifty %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> fifty_sum

full_train %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> full_sum

full_sum
```

```{r}
fifty_sum
```

```{r}
full_sum
```


## Classify Image
```{r}

pred_fun <- function(...){
  p <- predict(...)
  return(as.matrix(as.numeric(p[, 1, drop = TRUE]))) 
}

getStack <- function(dir) {
  list.files(dir, pattern = ".tif", full.names = TRUE ) %>% 
    raster::stack() %>%
    return()
}

hsv_seg <- raster::brick("clean_data/quadrats/quadrat34/hsv_seg_6_4.5_50.tif")
extent(hsv_seg) <- raster::extent(c(0, 4032, 0, 3024))

contrast <- raster::brick("clean_data/quadrats/quadrat34/hsv_contrast_L3_W7.tif")
extent(contrast) <- raster::extent(c(0, 4032, 0, 3024))

hsv <- raster::brick("clean_data/quadrats/quadrat34/hsv.tif")
extent(hsv) <- raster::extent(c(0, 4032, 0, 3024))

stack <- stack(hsv_seg, contrast, hsv)


stack %>% 
  raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  "outputs/forward_selection/classified34.tif", 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE)  -> predict_raster
extent(predict_raster) <-  raster::extent(c(0, 4032, 0, 3024))


( p_pred <- ggR(predict_raster, maxpixels = 5e+05, forceCat = TRUE, geom_raster = TRUE) +
    scale_fill_discrete(name = "Class") + theme_minimal() )


ggRGB(predict_raster, r = 1, g = 2, b = 3) 

classify_image <- function(quadrat_dir, rf_fit){
    quadrat <- quadrat_dir %>% str_split("/") %>% .[[1]] %>% .[3]
    
    file_to_write <- paste0('clean_data/classified/', quadrat, '.tif')

    quadrat_dir %>% 
                getStack() %>%
                raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  file_to_write, 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE) 

    return(file_to_write)
}
```

## First Run
```{r}

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"),
              
              color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"),
              accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))
```


```{r}
ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5),
             aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```




## Look at first layers
```{r}


orig_data <- data[1:4, 1:4][-1,][-1,]
colnames(orig_data) <- c( "","RGB", "HSV", "LAB")

orig_data
orig_data 

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"), color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"), accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))


ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5), aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```


## Plot Accuracy over layers
```{r}


df <- tibble(step = seq(1,6), accuracy=c(89.0, 91.85, 92.43, 92.43, 92.55, 92.92), layer= c("hsv", " + contrast (7)", " + hsv segmented", " + contrast (5)", " + lab segmented", " + contrast (3)"))
df

ggplot(df) +
  geom_line(mapping = aes(x = step, y = accuracy) )+ 
   geom_text(aes(label = accuracy, x = step, y = accuracy, vjust = -0.5)) + 
  geom_text(position = position_dodge(width= 0.5), aes(label = layer, x = step, y = accuracy, vjust = -3), color = "brown", size = 3.5) + 
   scale_x_continuous(breaks = scales::pretty_breaks(n = 5))  +
  ylim(87.5, 95) +
  xlab("Step") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold"),

    )
  
```

```{r}
library(ggplot2)
 
# create a dataset
specie <- c(rep("sorgho" , 3) , rep("poacee" , 3) , rep("banana" , 3) , rep("triticum" , 3) )
condition <- rep(c("normal" , "stress" , "Nitrogen") , 4)
value <- abs(rnorm(12 , 0 , 15))
data <- data.frame(specie,condition,value)
data

```


## Set up
```{r}
train_values <- train_values %>% transform(label = as.factor(label)) %>% tibble()
val_values <- val_values %>% transform(label = as.factor(label)) %>% tibble() 


  rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()

feature_names <- names(train_values)[-1]

```


## Get Accuracies
```{r}
get_layer_accuracy <- function(feature_name, train_values, val_values){
  rf_fit <- rf_pixel_model %>% fit(label ~ get(feature_name), data = train_values)
  
  val_pred <- predict(rf_fit, val_values) %>% 
      bind_cols(predict(rf_fit, val_values, type = "prob")) %>%
      bind_cols(val_values %>% dplyr::select(label)) 
    
 # val_pred %>% conf_mat(truth = label, .pred_class)
  val_pred %>% 
    accuracy(truth = label, .pred_class) %>% bind_cols(tibble( layer = feature_name)) %>%
    return()
}


feature_names %>% 
  map(.f = get_layer_accuracy,
      train_values = train_values, val_values = val_values) %>% bind_rows() -> accuracies

```




