---
title: "training_classifier"
author: "Jackson Krebsbach"
date: "7/31/2021"
output: html_document
---


## Load Libraries
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir=normalizePath("../..")) #set working directory to the project directory
library(tidyverse)
library(tidymodels)
library(ranger)
library(randomForest)
library(RStoolbox)
library(sf)
```


## Source Files and build classifier model
```{r, echo=FALSE, results=FALSE, message=FALSE, include=FALSE }
source('./code/helpers/classify_helpers.R')
show_engines("rand_forest")
rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()
```


## Get a list of clean pixels that make up a training, validation, and testing set
```{r}
'%!in%' <- function(x,y)!('%in%'(x,y))

#List of all the polygons that have errors or need to be removed
problem_polygons <- read_csv("clean_data/polygons_to_remove.csv") %>%
  mutate(quadrat = quadrat - 33) %>%
  mutate(key = paste0(quadrat,"_",poly_num))


#List of class changes that need to be done on the polygons
poly_classes_to_change <- read_csv("clean_data/polygon_class_changes.csv") %>%
  mutate(quadrat = as.numeric(quadrat - 33)) %>%
  mutate(key = paste0(quadrat,"_",poly_num))%>%
  dplyr::select(c(key, class_to_change_to))


#All the pixel values from every polygon
pixels <- readRDS('clean_data/rdata/pixel_values/features/poly_pixels.rds') %>%
  as_tibble() %>% 
  mutate(key = paste0(quadrat,"_",poly_num)) %>%
  filter(key %!in% problem_polygons$key) 


# Remove the polygons with errors and mutate the ones that need a class change
clean_pixels <- pixels %>%
  left_join(poly_classes_to_change) %>%
  mutate(label = as.factor(label), class_to_change_to = as.factor(class_to_change_to)) %>%
  mutate(label = case_when(is.na(class_to_change_to) ~ label,
                           !is.na(class_to_change_to) ~ class_to_change_to)) %>%
  dplyr::select(-class_to_change_to)
```


## Train test split
```{r}
full_train <- clean_pixels %>% 
  filter(train_val == 'train')
full_val <- clean_pixels %>%
  filter(train_val == 'val')
```


## Sample 10 pixels per polygon 
```{r}

PIXELS_PER_POLYGON <- 5

subset_training <- full_train %>%
  group_by(key) %>%
  slice_sample(n = PIXELS_PER_POLYGON) %>% # n is the number of pixels per polygon that we want to sample
  ungroup()

subset_validation <- full_val %>%
  group_by(key) %>%
  slice_sample(n = PIXELS_PER_POLYGON) %>%
  ungroup()

conf_matrix <- classify_train_val(train = subset_training, val = subset_validation)
```


## Define Function to train a classifier and save the data

Parameters: Training set, Validation set, Model, base for the output path, save flag to save the data

```{r}

classify_train_val <- function(train, val, model = rf_pixel_model, out_path , save = TRUE){
  if(!dir.exists(out_base_path)){dir.create(out_base_path)}
  
  rf_fit <- model  %>% fit(label ~ hsv_seg_6_4.5_50.1 + hsv_seg_6_4.5_50.2 + hsv_seg_6_4.5_50.3 +
                                   hsv_contrast_L3_W7 + hsv.1 + hsv.2 + hsv.3, data = train)
  
    val <- val %>%
    drop_na()
  
  val_pred <- predict(rf_fit, val) %>% 
    bind_cols(predict(rf_fit, val, type = "prob")) %>%
    bind_cols(val %>% dplyr::select(label,quadrat, poly_num, area)) 
  
  val_pred %>%
    conf_mat(truth = label, .pred_class) -> val_confusion_matrix
  
  val_pred %>%
    accuracy(truth = label, .pred_class) -> val_accuracy
  
  train_accuracy <- 1 - rf_fit$fit$prediction.error
  
  print(val_accuracy)
  print(train_accuracy)
  
  saveRDS(val_confusion_matrix, out_path)
  return(val_confusion_matrix)
}
```



## Train on train set and predict on validation set
```{r}
train <- small_training_set
val <- small_validation_set

rf_fit <- rf_pixel_model %>% fit(label ~ hsv_seg_6_4.5_50.1 + hsv_seg_6_4.5_50.2 + hsv_seg_6_4.5_50.3 +
                                   hsv_contrast_L3_W7 + hsv.1 + hsv.2 + hsv.3, data = train)

val <- val %>%
  drop_na()

val_pred <- predict(rf_fit, val) %>% 
  bind_cols(predict(rf_fit, val, type = "prob")) %>%
  bind_cols(val %>% dplyr::select(label,quadrat, poly_num, area)) 

val_pred %>%
  conf_mat(truth = label, .pred_class) -> val_confusion_matrix

val_pred %>%
  accuracy(truth = label, .pred_class) -> val_accuracy

train_accuracy <- 1 - rf_fit$fit$prediction.error

print(val_accuracy)
print(train_accuracy)

#saveRDS(val_pred, "./clean_data/pixel_values/predictions/val_pred_small_training_set.rds")
```


## Classify Image
```{r}

pred_fun <- function(...){
  p <- predict(...)
  return(as.matrix(as.numeric(p[, 1, drop = TRUE]))) 
}

getStack <- function(dir) {
  list.files(dir, pattern = ".tif", full.names = TRUE ) %>% 
    raster::stack() %>%
    return()
}

hsv_seg <- raster::brick("clean_data/quadrats/quadrat34/hsv_seg_6_4.5_50.tif")
extent(hsv_seg) <- raster::extent(c(0, 4032, 0, 3024))

contrast <- raster::brick("clean_data/quadrats/quadrat34/hsv_contrast_L3_W7.tif")
extent(contrast) <- raster::extent(c(0, 4032, 0, 3024))

hsv <- raster::brick("clean_data/quadrats/quadrat34/hsv.tif")
extent(hsv) <- raster::extent(c(0, 4032, 0, 3024))

stack <- stack(hsv_seg, contrast, hsv)


stack %>% 
  raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  "outputs/forward_selection/classified34.tif", 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE)  -> predict_raster
extent(predict_raster) <-  raster::extent(c(0, 4032, 0, 3024))


( p_pred <- ggR(predict_raster, maxpixels = 5e+05, forceCat = TRUE, geom_raster = TRUE) +
    scale_fill_discrete(name = "Class") + theme_minimal() )


ggRGB(predict_raster, r = 1, g = 2, b = 3) 

classify_image <- function(quadrat_dir, rf_fit){
    quadrat <- quadrat_dir %>% str_split("/") %>% .[[1]] %>% .[3]
    
    file_to_write <- paste0('clean_data/classified/', quadrat, '.tif')

    quadrat_dir %>% 
                getStack() %>%
                raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  file_to_write, 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE) 

    return(file_to_write)
}
```

## First Run
```{r}

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"),
              
              color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"),
              accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))
```


```{r}
ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5),
             aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```




## Look at first layers
```{r}


orig_data <- data[1:4, 1:4][-1,][-1,]
colnames(orig_data) <- c( "","RGB", "HSV", "LAB")

orig_data
orig_data 

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"), color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"), accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))


ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5), aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```


## Plot Accuracy over layers
```{r}


df <- tibble(step = seq(1,6), accuracy=c(89.0, 91.85, 92.43, 92.43, 92.55, 92.92), layer= c("hsv", " + contrast (7)", " + hsv segmented", " + contrast (5)", " + lab segmented", " + contrast (3)"))
df

ggplot(df) +
  geom_line(mapping = aes(x = step, y = accuracy) )+ 
   geom_text(aes(label = accuracy, x = step, y = accuracy, vjust = -0.5)) + 
  geom_text(position = position_dodge(width= 0.5), aes(label = layer, x = step, y = accuracy, vjust = -3), color = "brown", size = 3.5) + 
   scale_x_continuous(breaks = scales::pretty_breaks(n = 5))  +
  ylim(87.5, 95) +
  xlab("Step") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold"),

    )
  
```

```{r}
library(ggplot2)
 
# create a dataset
specie <- c(rep("sorgho" , 3) , rep("poacee" , 3) , rep("banana" , 3) , rep("triticum" , 3) )
condition <- rep(c("normal" , "stress" , "Nitrogen") , 4)
value <- abs(rnorm(12 , 0 , 15))
data <- data.frame(specie,condition,value)
data

```


## Set up
```{r}
train_values <- train_values %>% transform(label = as.factor(label)) %>% tibble()
val_values <- val_values %>% transform(label = as.factor(label)) %>% tibble() 


  rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()

feature_names <- names(train_values)[-1]

```


## Get Accuracies
```{r}
get_layer_accuracy <- function(feature_name, train_values, val_values){
  rf_fit <- rf_pixel_model %>% fit(label ~ get(feature_name), data = train_values)
  
  val_pred <- predict(rf_fit, val_values) %>% 
      bind_cols(predict(rf_fit, val_values, type = "prob")) %>%
      bind_cols(val_values %>% dplyr::select(label)) 
    
 # val_pred %>% conf_mat(truth = label, .pred_class)
  val_pred %>% 
    accuracy(truth = label, .pred_class) %>% bind_cols(tibble( layer = feature_name)) %>%
    return()
}


feature_names %>% 
  map(.f = get_layer_accuracy,
      train_values = train_values, val_values = val_values) %>% bind_rows() -> accuracies

```




