---
title: "training_classifier"
author: "Jackson Krebsbach"
date: "7/31/2021"
output: html_document
---

## Load Libraries
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir=normalizePath("../..")) #set working directory to the project directory
library(tidyverse)
library(tidymodels)
library(ranger)
library(rlist)
```


## Source Files and build classifier model
```{r, echo=FALSE, results=FALSE, message=FALSE, include=FALSE }
source('./code/helpers/classify_helpers.R')
show_engines("rand_forest")
rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()
```


## Get a list of clean pixels that make up a training, validation, and testing set
```{r}
'%!in%' <- function(x,y)!('%in%'(x,y))

#List of all the polygons that have errors or need to be removed
problem_polygons <- read_csv("clean_data/polygons_to_remove.csv") %>%
  mutate(quadrat = quadrat - 33) %>%
  mutate(key = paste0(quadrat,"_",poly_num))

#List of class changes that need to be done on the polygons
poly_classes_to_change <- read_csv("clean_data/polygon_class_changes.csv") %>%
  mutate(quadrat = as.numeric(quadrat - 33)) %>%
  mutate(key = paste0(quadrat,"_",poly_num))%>%
  dplyr::select(c(key, class_to_change_to))


#All the pixel values from every polygon
pixels <- readRDS('clean_data/rdata/pixel_values/pixels.rds') %>%
  as_tibble() %>% 
  mutate(key = paste0(quadrat,"_",poly_num)) %>%
  filter(key %!in% problem_polygons$key) 

# Remove the polygons with errors and mutate the ones that need a class change
clean_pixels <- pixels %>%
  left_join(poly_classes_to_change) %>%
  mutate(label = as.factor(label), class_to_change_to = as.factor(class_to_change_to)) %>%
  mutate(label = case_when(is.na(class_to_change_to) ~ label,
                           !is.na(class_to_change_to) ~ class_to_change_to)) %>%
  dplyr::select(-class_to_change_to)
```


## Train test split
```{r}
full_train <- clean_pixels %>% 
  filter(train_val == 'train') %>%
  select(-c(train_val, cell, dir, inpath, area, poly_num, quadrat, key))


full_val <- clean_pixels %>%
  filter(train_val == 'val') %>%
  select(-train_val)
```

## Sample 10 pixels per polygon 
```{r}
PIXELS <- 1000

subset_training <- full_train %>%
  group_by(label) %>%
  slice_sample(n = PIXELS) %>% # n is the number of pixels per polygon that we want to sample
  ungroup()
#conf_matrix <- classify_train_val(train = subset_training, val = full_val)
```


## Test Single Layer
```{r}
##Returns accuracy and importance tibble
test_single_layer <- function(train, val, model) {
  print('Starting to train')
  rf_fit <-  model %>%
    fit(label ~ ., data = train)
  
  val <- val %>%
    drop_na()
  
  val_pred <- predict(rf_fit, val) %>%
    bind_cols(predict(rf_fit, val, type = "prob")) %>%
    bind_cols(val %>% dplyr::select(label, dir, poly_num, area))
  
  val_pred %>%
    accuracy(truth = label, .pred_class) -> val_accuracy
  
  
  importance <- rf_fit$fit$variable.importance
    print('Ending the train')
  return(list(val_accuracy$.estimate, importance))
  
}

```


## Define Variables to implement feature selection
```{r}
train <- subset_training %>%
  drop_na() %>%
  select(c(label, 5,4,10,28, 30 ,40, 21))

val <- full_val

NUM_RUNS_PER_FEATURE <-3
NUM_OF_FEATURES <- 4


all_features <- train %>%
  select(-label) %>%
  names()

features_added <- c()


data <- list()

for( i in 1:NUM_OF_FEATURES){
  
  
    features_to_test <- all_features %>%
        list.filter(. %!in% features_added )
  

   last <- features_added 
   
   forward_selection_data <- tibble(feature = character(),
                                    mean_val_accuracy = numeric(),
                                    sd_val_accuracy = numeric(),
                                    importance = numeric())
     if(!is.null(last)){
        for(imps in 1:length(last)){
            forward_selection_data %>% 
                 add_column("{last[imps]}_importance":= numeric()) -> forward_selection_data
      }
    }
   
    for(j in 1:length(features_to_test)){
      
      t <- features_added %>% 
        list.append(features_to_test[j]) %>%
        list.append('label')
      
      train_set <- train[t]
      
      v <- val
      
      model <- rf_pixel_model
      
      total_val_accuracy <- list()
      
      for(run in 1:NUM_RUNS_PER_FEATURE){
        out <- test_single_layer(train_set ,v, model)
        importance <- out[[2]][features_to_test[j]]
        val_accuracy <- out[[1]]
        total_val_accuracy[[run]] <- val_accuracy
      }
      
      mean <- total_val_accuracy %>%
        unlist %>%
        mean
      
      sd <- total_val_accuracy %>%
        unlist %>%
        sd
  
     if(i!=1) {
      prev <- out[[2]][features_added] %>%
          .[!is.na(.)] %>%
          bind_rows() %>%
          pivot_longer(cols = everything())
      }
     
    
    new_row <- tibble( feature =  features_to_test[j],
                               mean_val_accuracy = mean,
                               sd_val_accuracy = sd,
                              importance = importance)
     if(exists('prev')){
        for(imps in 1:nrow(prev)){
          slice <- prev %>% slice(imps)
            new_row %>% 
                 add_column("{slice$name}_importance":= slice$value) -> new_row
      }
    }
      
      forward_selection_data %>%
        bind_rows(new_row) -> forward_selection_data
   }

   
   forward_selection_data  %>%
     filter(mean_val_accuracy == max(mean_val_accuracy)) -> max
  
   
   forward_selection_data %>% 
     add_column("{max$feature}_importance":= max$importance) -> forward_selection_data
   
     
   features_added %>%
     append(max$feature) -> features_added
   
   data[[i]] <- forward_selection_data
   
}
#out <- test_layer(train = train, val = val, model = rf_pixel_model)
```

## Train on train set and predict on validation set
```{r}
train <- subset_training
#train$random <- runif(nrow(train), min = 0, max = 1)
val <- full_val

rf_fit <- rf_pixel_model %>%
  fit(label ~  ., data = train)

val <- val %>%
  drop_na()

val_pred <- predict(rf_fit, val) %>% 
  bind_cols(predict(rf_fit, val, type = "prob")) %>%
  bind_cols(val %>% dplyr::select(label, dir, poly_num, area)) 

val_pred %>%
  conf_mat(truth = label, .pred_class) -> val_confusion_matrix

val_pred %>%
  accuracy(truth = label, .pred_class) -> val_accuracy

train_accuracy <- 1 - rf_fit$fit$prediction.error

c <- val_confusion_matrix %>%
  get_percentage_confusion_matrix()

```

## Look at importance
```{r}
importance <- rf_fit$fit$variable.importance

m <- max(importance)
min <- min(importance)
print(m)
print(min)
(importance)
```

## Saving Data
```{r}
#OUT_FILE <-"all_pixels"
# saveRDS(val_pred, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_val_pixels.rds" ))
# saveRDS(c, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_percentage_conf_mat.rds" ))
# saveRDS(val_confusion_matrix, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_count_conf_mat.rds" ))
# saveRDS(val_accuracy, paste0("./clean_data/rdata/pixel_values/predictions/",OUT_FILE, "_validation_accuracy.rds" ))
```

## Get Percentage Confusion Matrix
```{r}
# Takes in direct ouput from conf_mat
get_percentage_confusion_matrix <- function(conf_matrix){
  
  conf_matrix[[1]] %>%
    as_tibble() %>%
    pivot_wider(names_from = Truth, values_from = n) %>%
    mutate(`dead vegetation` = `dead vegetation`/ sum(`dead vegetation`),
           `live vegetation` = `live vegetation`/ sum(`live vegetation`),
           sand = sand/sum(sand)) %>%
    return()
}
```



## Saving Data
```{r}
saveRDS(full_train, './clean_data/rdata/pixel_values/training_set.rds')
saveRDS(full_val, './clean_data/rdata/pixel_values/validation_set.rds')

```



```{r}
ten_pixels <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(28783, 667, 2606),
                     live_veg= c(894,75203, 73),
                     sand = c(9833, 377, 345554))

fifty <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(27642, 755,3659 ),
                     live_veg= c(883,75193, 94),
                     sand = c(1442, 182, 354140))

full_train <- tibble(pred = c("dead_veg", "live_veg", "sand"),
                     dead_veg= c(27586, 797, 3673),
                     live_veg= c(883, 75188, 99),
                     sand = c(1399, 182, 354183))
fifty
```


```{r}
options(digits = 2)
ten_pixels %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> ten_sum

fifty %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> fifty_sum

full_train %>%
  mutate(dead_veg = dead_veg/sum(dead_veg), live_veg = live_veg/sum(live_veg), sand = sand/sum(sand)) -> full_sum

full_sum
```



## Classify Image
```{r}

pred_fun <- function(...){
  p <- predict(...)
  return(as.matrix(as.numeric(p[, 1, drop = TRUE]))) 
}

getStack <- function(dir) {
  list.files(dir, pattern = ".tif", full.names = TRUE ) %>% 
    raster::stack() %>%
    return()
}

hsv_seg <- raster::brick("clean_data/quadrats/quadrat34/hsv_seg_6_4.5_50.tif")
extent(hsv_seg) <- raster::extent(c(0, 4032, 0, 3024))

contrast <- raster::brick("clean_data/quadrats/quadrat34/hsv_contrast_L3_W7.tif")
extent(contrast) <- raster::extent(c(0, 4032, 0, 3024))

hsv <- raster::brick("clean_data/quadrats/quadrat34/hsv.tif")
extent(hsv) <- raster::extent(c(0, 4032, 0, 3024))

stack <- stack(hsv_seg, contrast, hsv)


stack %>% 
  raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  "outputs/forward_selection/classified34.tif", 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE)  -> predict_raster
extent(predict_raster) <-  raster::extent(c(0, 4032, 0, 3024))


( p_pred <- ggR(predict_raster, maxpixels = 5e+05, forceCat = TRUE, geom_raster = TRUE) +
    scale_fill_discrete(name = "Class") + theme_minimal() )


ggRGB(predict_raster, r = 1, g = 2, b = 3) 

classify_image <- function(quadrat_dir, rf_fit){
    quadrat <- quadrat_dir %>% str_split("/") %>% .[[1]] %>% .[3]
    
    file_to_write <- paste0('clean_data/classified/', quadrat, '.tif')

    quadrat_dir %>% 
                getStack() %>%
                raster::predict(rf_fit, type = "class", fun = pred_fun, filename =  file_to_write, 
                        datatype = 'INT1U', format = "GTiff", overwrite = TRUE) 

    return(file_to_write)
}
```

## First Run
```{r}

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"),
              
              color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"),
              accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))
```


```{r}
ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5),
             aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```




## Look at first layers
```{r}


orig_data <- data[1:4, 1:4][-1,][-1,]
colnames(orig_data) <- c( "","RGB", "HSV", "LAB")

orig_data
orig_data 

df <- tibble( data_set = c("training", "training","training", "validation","validation", "validation"), color_space = c("RGB", "HSV", "LAB","RGB", "HSV", "LAB"), accuracy = c(92.6, 93.3, 87.7, 88.2, 89.0, 74.2))
df %<>% mutate(data_set = as.factor(data_set))


ggplot(df, aes(color_space, accuracy)) + 
    geom_bar(aes(fill= data_set),position="dodge", stat="identity") +
   scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + 
   geom_text(position = position_dodge(width= 0.5), aes(label = accuracy, fill = data_set, vjust =-0.5)) +
   xlab("Color Space") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold")
    )+ guides(fill=guide_legend(title=" Data Set"))
  

```


## Plot Accuracy over layers
```{r}


df <- tibble(step = seq(1,6), accuracy=c(89.0, 91.85, 92.43, 92.43, 92.55, 92.92), layer= c("hsv", " + contrast (7)", " + hsv segmented", " + contrast (5)", " + lab segmented", " + contrast (3)"))
df

ggplot(df) +
  geom_line(mapping = aes(x = step, y = accuracy) )+ 
   geom_text(aes(label = accuracy, x = step, y = accuracy, vjust = -0.5)) + 
  geom_text(position = position_dodge(width= 0.5), aes(label = layer, x = step, y = accuracy, vjust = -3), color = "brown", size = 3.5) + 
   scale_x_continuous(breaks = scales::pretty_breaks(n = 5))  +
  ylim(87.5, 95) +
  xlab("Step") +
   ylab("Accuracy") +
   theme(
      axis.title.x = element_text( size=14, face="bold"),
      axis.title.y = element_text( size=14, face="bold"),

    )
  
```

```{r}
library(ggplot2)
 
# create a dataset
specie <- c(rep("sorgho" , 3) , rep("poacee" , 3) , rep("banana" , 3) , rep("triticum" , 3) )
condition <- rep(c("normal" , "stress" , "Nitrogen") , 4)
value <- abs(rnorm(12 , 0 , 15))
data <- data.frame(specie,condition,value)
data

```


## Set up
```{r}
train_values <- train_values %>% transform(label = as.factor(label)) %>% tibble()
val_values <- val_values %>% transform(label = as.factor(label)) %>% tibble() 


  rf_pixel_model <- rand_forest() %>%
                  set_engine("ranger", importance = "impurity") %>%
                  set_mode("classification") %>%
                  translate()

feature_names <- names(train_values)[-1]

```


## Get Accuracies
```{r}
get_layer_accuracy <- function(feature_name, train_values, val_values){
  rf_fit <- rf_pixel_model %>% fit(label ~ get(feature_name), data = train_values)
  
  val_pred <- predict(rf_fit, val_values) %>% 
      bind_cols(predict(rf_fit, val_values, type = "prob")) %>%
      bind_cols(val_values %>% dplyr::select(label)) 
    
 # val_pred %>% conf_mat(truth = label, .pred_class)
  val_pred %>% 
    accuracy(truth = label, .pred_class) %>% bind_cols(tibble( layer = feature_name)) %>%
    return()
}


feature_names %>% 
  map(.f = get_layer_accuracy,
      train_values = train_values, val_values = val_values) %>% bind_rows() -> accuracies

```




